{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìä **Pipeline de Processamento de Linguagem Natural (NLP)**\n",
        "\n",
        "## **Do Texto Bruto √† Modelagem Preditiva**\n",
        "\n",
        "Neste projeto aplico t√©cnicas cl√°ssicas de Processamento de Linguagem Natural (NLP)\n",
        "para transformar textos em representa√ß√µes num√©ricas e aplicar modelos de Machine Learning.\n",
        "\n",
        "O objetivo √© demonstrar dom√≠nio pr√°tico do pipeline completo e an√°lise de texto com t√©cnicas de NLP.\n",
        "\n",
        "Cada etapa est√° organizada com descri√ß√£o conceitual e explica√ß√£o do que est√° sendo realizado.\n",
        "\n"
      ],
      "metadata": {
        "id": "lqrAxw-ZvULI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üîé **Pipeline do Projeto**\n",
        "\n",
        "Este notebook segue as seguintes etapas:\n",
        "\n",
        "1. **Prepara√ß√£o dos dados** ‚Äì `pandas`, `numpy` e carregamento da base.  \n",
        "\n",
        "2. **Pr√©-processamento textual** ‚Äì `regex`, `nltk` (stopwords), padroniza√ß√£o para lowercase e limpeza de caracteres.  \n",
        "\n",
        "3. **Vetoriza√ß√£o** ‚Äì `CountVectorizer` (Bag of Words) e `TfidfVectorizer` (TF-IDF) para transforma√ß√£o do texto em matriz esparsa.  \n",
        "\n",
        "4. **Similaridade** ‚Äì Similaridade do cosseno (`cosine similarity`) para medir proximidade entre documentos.  \n",
        "\n",
        "5. **Modelagem** ‚Äì `LogisticRegression` (scikit-learn) para classifica√ß√£o supervisionada.  \n",
        "\n",
        "6. **Avalia√ß√£o** ‚Äì `classification_report` e `confusion_matrix` para an√°lise de desempenho.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Gdf2U-DhvXfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importa√ß√£o das Bibliotecas** üß∞"
      ],
      "metadata": {
        "id": "yswhv-HbvdDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä Manipula√ß√£o de dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# üßπ Processamento de texto\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# üî¢ Vetoriza√ß√£o (Representa√ß√£o Num√©rica)\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# üß† Modelos Baseados em Transformers\n",
        "from transformers import pipeline\n",
        "\n",
        "# üìê Similaridade entre documentos\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# üß† Topic Modeling\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# ü§ñ Modelagem e Avalia√ß√£o (Machine Learning Cl√°ssico)\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "6sesq07Xvnp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ **Etapa 1 ‚Äì Coleta e Carregamento dos Dados** üíæ\n",
        "\n",
        "Nesta se√ß√£o realizamos a clonagem do reposit√≥rio p√∫blico contendo o dataset\n",
        "de reviews de e-commerce.\n",
        "\n",
        "Os dados utilizados s√£o **avalia√ß√µes de produtos do Mercado Livre**,\n",
        "armazenadas em formato JSON.\n",
        "\n",
        "O c√≥digo abaixo:\n",
        "\n",
        "- Clona o reposit√≥rio via GitHub\n",
        "- Lista os arquivos dispon√≠veis\n",
        "- Carrega os arquivos JSON\n",
        "- Concatena os dados em um √∫nico DataFrame para an√°lise"
      ],
      "metadata": {
        "id": "FxQbx7K0v-LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/octaprice/ecommerce-product-dataset.git\n",
        "!ls ecommerce-product-dataset/data/mercadolivre_com_br\n",
        "\n",
        "\n",
        "df1 = pd.read_json(\"ecommerce-product-dataset/data/mercadolivre_com_br/reviews_mercadolivre_com_br_1.json\")\n",
        "df2 = pd.read_json(\"ecommerce-product-dataset/data/mercadolivre_com_br/reviews_mercadolivre_com_br_2.json\")\n",
        "df = pd.concat([df1, df2], ignore_index=True)"
      ],
      "metadata": {
        "id": "x1yZv599wDdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ **Etapa 2 ‚Äì Modelos de Emo√ß√£o e An√°lise de Sentimento** üòäüé≠"
      ],
      "metadata": {
        "id": "-fdXyPLgwO4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta etapa utilizamos modelos baseados em **Transformers** capaz de capturar melhor o **contexto das frases** para analisar textos\n",
        "sob duas perspectivas:\n",
        "\n",
        "- üé≠ **An√°lise de Emo√ß√£o** ‚Üí identifica emo√ß√µes espec√≠ficas **(alegria, tristeza, raiva, medo, surpresa, nojo)**.\n",
        "- üòä **An√°lise de Sentimento** ‚Üí classifica a polaridade geral **(positivo, neutro, negativo)**."
      ],
      "metadata": {
        "id": "OCP1E6hJwMhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü§ñ **Carregamento do Modelo de Emo√ß√£o** üé≠"
      ],
      "metadata": {
        "id": "kPaFG0L2w37I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificador_emocao = pipeline(\n",
        "    task=\"text-classification\",\n",
        "    model=\"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XbNpTnqzw-oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîé **Fun√ß√£o para Detec√ß√£o de Emo√ß√£o**\n",
        "\n",
        "Recebe um texto e retorna a emo√ß√£o predominante identificada pelo modelo pr√©-treinado."
      ],
      "metadata": {
        "id": "7KtCjSDhyI2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detectar_emocao(texto):\n",
        "\n",
        "    texto = str(texto)[:512]\n",
        "    resultado = classificador_emocao(texto)[0]\n",
        "\n",
        "    return resultado['label']"
      ],
      "metadata": {
        "id": "5SfobKubycYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Aplica√ß√£o do Modelo em uma Amostra do Dataset**"
      ],
      "metadata": {
        "id": "_8JZbewqyj4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona amostra para demonstra√ß√£o\n",
        "df_demo = df.sample(200, random_state=42).copy()\n",
        "\n",
        "# Executa infer√™ncia em lote\n",
        "resultados = classificador_emocao(\n",
        "    df_demo[\"content\"].astype(str).tolist()\n",
        ")\n",
        "\n",
        "# Armazena emo√ß√µes previstas\n",
        "df_demo[\"emocao\"] = [r[\"label\"] for r in resultados]\n",
        "\n",
        "df_demo.head()"
      ],
      "metadata": {
        "id": "ovDiu_AwylUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü§ñ **Carregamento do Modelo de Sentimento** üòä"
      ],
      "metadata": {
        "id": "AmFZaZH9y4ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificador_sentimento = pipeline(\n",
        "    task=\"sentiment-analysis\",\n",
        "    model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
        ")\n",
        "\n",
        "def detectar_sentimento(texto):\n",
        "    texto = str(texto)[:512]\n",
        "    resultado = classificador_sentimento(texto)[0]\n",
        "    return resultado['label']"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rTzISBElzDqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Aplica√ß√£o do Modelo na Mesma Amostra**"
      ],
      "metadata": {
        "id": "W-8ZzdK2zPvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_sentimento = classificador_sentimento(\n",
        "    df_demo[\"content\"].astype(str).tolist()\n",
        ")\n",
        "\n",
        "df_demo[\"sentimento\"] = [r[\"label\"] for r in resultados_sentimento]"
      ],
      "metadata": {
        "id": "DFuJ1HpGzN8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üëÄ Visualiza√ß√£o e An√°lise das Emo√ß√µes**"
      ],
      "metadata": {
        "id": "hu-ZEAF2zYC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_demo[['content','emocao','sentimento']].sample(5)"
      ],
      "metadata": {
        "id": "cpiT6himzY7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_demo['sentimento'].value_counts().reset_index()"
      ],
      "metadata": {
        "id": "w7wiAnfKzdXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ **Etapa 3 ‚Äì Detec√ß√£o de Inconsist√™ncias** ‚ö†Ô∏è\n",
        "\n"
      ],
      "metadata": {
        "id": "y-_GV2bzz3vA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìä **Objetivo**\n",
        "Identificar contradi√ß√µes entre a **nota (rating)** e o **sentimento previsto no texto**.\n",
        "\n",
        "Consideramos inconsist√™ncia quando:\n",
        "\n",
        "- ‚≠ê Nota alta (4 ou 5) ‚Üí sentimento negativo  \n",
        "- ‚≠ê Nota baixa (1 ou 2) ‚Üí sentimento positivo  \n",
        "\n",
        "Essa an√°lise ajuda a identificar poss√≠veis erros de rotulagem,\n",
        "ironia textual ou limita√ß√µes do modelo."
      ],
      "metadata": {
        "id": "FUhSJqXiz9MJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîé **Defini√ß√£o das regras de inconsist√™ncia**"
      ],
      "metadata": {
        "id": "txF6z3q10Itd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inconsistencias = df_demo[\n",
        "    (\n",
        "        (df_demo[\"rating\"] >= 4) & (df_demo[\"sentimento\"] == \"negative\")\n",
        "    )\n",
        "    |\n",
        "    (\n",
        "        (df_demo[\"rating\"] <= 2) & (df_demo[\"sentimento\"] == \"positive\")\n",
        "    )\n",
        "]\n",
        "\n",
        "# Visualizar exemplos\n",
        "inconsistencias[[\"content\", \"rating\", \"sentimento\"]].head()"
      ],
      "metadata": {
        "id": "9Ex_UhT30KA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Inconsistentes:', len(inconsistencias))\n",
        "print('%:', round(len(inconsistencias)/len(df_demo)*100, 2))"
      ],
      "metadata": {
        "id": "p2x4lDuE0kG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìå **Interpreta√ß√£o**\n",
        "\n",
        "A presen√ßa de inconsist√™ncias pode indicar:\n",
        "\n",
        "- Uso ir√¥nico da linguagem\n",
        "- Ambiguidade textual\n",
        "- Diferen√ßa entre percep√ß√£o emocional e avalia√ß√£o final\n",
        "- Limita√ß√µes do modelo pr√©-treinado\n",
        "\n",
        "Essa etapa adiciona uma camada anal√≠tica ao projeto,\n",
        "indo al√©m da simples classifica√ß√£o autom√°tica.\n",
        "\n",
        "**Reviews muito curtas apresentaram maior propor√ß√£o de inconsist√™ncias, sugerindo que a baixa quantidade de contexto textual pode dificultar a interpreta√ß√£o correta pelo modelo.**"
      ],
      "metadata": {
        "id": "NInPRfJ80R14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ **Etapa 4 ‚Äì Detec√ß√£o de Temas (Topic Modeling)** üß©"
      ],
      "metadata": {
        "id": "o_Uxtq_y4_8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìå **Objetivo**\n",
        "Identificar automaticamente os principais temas presentes nas reviews,\n",
        "utilizando modelagem n√£o supervisionada.\n",
        "\n",
        "Aplicamos:\n",
        "- **Bag of Words (CountVectorizer)** para transformar texto em matriz num√©rica  \n",
        "- **LDA (Latent Dirichlet Allocation)** para descobrir grupos de palavras recorrentes  \n",
        "\n",
        "Essa abordagem permite responder:\n",
        "\n",
        "> ‚ÄúQuais s√£o os principais assuntos discutidos nas avalia√ß√µes?‚Äù"
      ],
      "metadata": {
        "id": "EAUgPDWN5F51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üî¢ **Vetoriza√ß√£o (Bag of Words)**"
      ],
      "metadata": {
        "id": "VIU6hcco5JVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopwords em portugu√™s\n",
        "nltk.download(\"stopwords\")\n",
        "stopwords_pt = stopwords.words(\"portuguese\")\n",
        "\n",
        "# Vetoriza√ß√£o do texto\n",
        "vetorizador = CountVectorizer(\n",
        "    stop_words=stopwords_pt,\n",
        "    max_features=1000\n",
        ")\n",
        "\n",
        "matriz_texto = vetorizador.fit_transform(df_demo[\"content\"])"
      ],
      "metadata": {
        "id": "FPREVE1M5NZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **üß† Treinamento do Modelo LDA**"
      ],
      "metadata": {
        "id": "TEAEekTt5RnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinamento do modelo de t√≥picos\n",
        "modelo_lda = LatentDirichletAllocation(\n",
        "    n_components=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo_lda.fit(matriz_texto)"
      ],
      "metadata": {
        "id": "EXr_rAX05Xom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîé **Principais Palavras por Tema**"
      ],
      "metadata": {
        "id": "4_eIuvdv5sT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar palavras mais relevantes de cada tema\n",
        "palavras = vetorizador.get_feature_names_out()\n",
        "\n",
        "for indice_tema, tema in enumerate(modelo_lda.components_):\n",
        "    principais_palavras = [palavras[i] for i in tema.argsort()[-10:]]\n",
        "    print(f\"Tema {indice_tema+1}\")\n",
        "    print(principais_palavras)"
      ],
      "metadata": {
        "id": "WEb8i7Nd5uEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìä **An√°lise dos Temas (Amostra)**\n",
        "\n",
        "Identificamos o **tema dominante** de cada review com base na maior\n",
        "probabilidade atribu√≠da pelo LDA.\n",
        "\n",
        "Em seguida, analisamos a distribui√ß√£o dos temas\n",
        "e sua rela√ß√£o com o sentimento."
      ],
      "metadata": {
        "id": "iNerCZ6D7PI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Identificar tema principal de cada review\n",
        "matriz_temas = modelo_lda.transform(matriz_texto)\n",
        "\n",
        "df_demo[\"tema_principal\"] = matriz_temas.argmax(axis=1)"
      ],
      "metadata": {
        "id": "VkmYH9q-7Rj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**An√°lise Estat√≠stica Descritiva dos temas**"
      ],
      "metadata": {
        "id": "g2M-vzzz7zl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_demo[\"tema_principal\"].value_counts().reset_index()"
      ],
      "metadata": {
        "id": "QBSYV-Wy71LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_demo.groupby('tema_principal')['rating'].mean().reset_index()"
      ],
      "metadata": {
        "id": "A9LhS59E78Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üòä **Distribui√ß√£o de Sentimento por Tema**\n",
        "\n",
        "Analisamos como o sentimento se distribui dentro de cada tema,\n",
        "permitindo identificar quais assuntos est√£o mais associados\n",
        "a avalia√ß√µes positivas ou negativas."
      ],
      "metadata": {
        "id": "72prMQyL77U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_demo.groupby([\"tema_principal\", \"sentimento\"]).size().unstack().reset_index()"
      ],
      "metadata": {
        "id": "wVOymtxi81U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ **Etapa 5 ‚Äì An√°lise de Similaridade Textual** üìê"
      ],
      "metadata": {
        "id": "KWGb-EMK9AK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üéØ Objetivo**\n",
        "\n",
        "Nesta etapa utilizamos **TF-IDF** para representar os textos\n",
        "e aplicamos **similaridade do cosseno** para medir proximidade entre reviews.\n",
        "\n",
        "Essa abordagem permite identificar textos semanticamente semelhantes,\n",
        "servindo como base para sistemas de recomenda√ß√£o ou busca textual."
      ],
      "metadata": {
        "id": "mZjK0a-a9KKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¢ **Representa√ß√£o vetorial com TF-IDF**\n"
      ],
      "metadata": {
        "id": "kBvT1vdA9fgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "stopwords_pt = stopwords.words(\"portuguese\")\n",
        "\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    stop_words=stopwords_pt,\n",
        "    min_df=5\n",
        ")\n",
        "\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df[\"content\"])"
      ],
      "metadata": {
        "id": "dcvL8ewq9k-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìö **Vocabul√°rio criado pelo modelo**"
      ],
      "metadata": {
        "id": "0KkKTUq09tCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_tfidf = tfidf_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "muW6vB1F9uE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìê **Similaridade do cosseno entre duas reviews**\n"
      ],
      "metadata": {
        "id": "qxnJuz0X9xaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i, j = 11, 20\n",
        "\n",
        "print(\"Review A:\\n\", df.loc[i, \"content\"])\n",
        "print(\"\\nReview B:\\n\", df.loc[j, \"content\"])\n",
        "\n",
        "similaridade = cosine_similarity(\n",
        "    X_tfidf[i],\n",
        "    X_tfidf[j]\n",
        ")[0][0]\n",
        "\n",
        "print(\"\\nSimilaridade:\", similaridade)"
      ],
      "metadata": {
        "id": "elcUoEGg90cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîé **Encontrar textos semelhantes a uma review espec√≠fica**"
      ],
      "metadata": {
        "id": "-YvpQitM942u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx_base = 11\n",
        "\n",
        "# Calcular similaridade com todas as reviews\n",
        "similaridades = cosine_similarity(\n",
        "    X_tfidf[idx_base],\n",
        "    X_tfidf\n",
        ")[0]\n",
        "\n",
        "# Ordenar por maior similaridade\n",
        "df_sim = (\n",
        "    df.assign(similaridade=similaridades)\n",
        "      .sort_values(\"similaridade\", ascending=False)\n",
        ")\n",
        "\n",
        "# Top 5 mais semelhantes (excluindo a pr√≥pria)\n",
        "df_sim.iloc[1:6][[\"rating\", \"similaridade\", \"content\"]]"
      ],
      "metadata": {
        "id": "xbEI_dcV950g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç **Busca sem√¢ntica a partir de um texto digitado**"
      ],
      "metadata": {
        "id": "vk8GVYs8-DUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "consulta = \"produto deixou meu cabelo macio e cheiroso\"\n",
        "\n",
        "vetor_consulta = tfidf_vectorizer.transform([consulta])\n",
        "\n",
        "similaridades_consulta = cosine_similarity(\n",
        "    vetor_consulta,\n",
        "    X_tfidf\n",
        ")[0]\n",
        "\n",
        "df_busca = (\n",
        "    df.assign(similaridade=similaridades_consulta)\n",
        "      .sort_values(\"similaridade\", ascending=False)\n",
        ")\n",
        "\n",
        "df_busca.head(5)[[\"rating\", \"similaridade\", \"content\"]]"
      ],
      "metadata": {
        "id": "gWuI6BO7-Gxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîπ **Etapa 6 ‚Äì Classifica√ß√£o de Texto com Regress√£o Log√≠stica** ü§ñ"
      ],
      "metadata": {
        "id": "CgpVG4Bn-ivS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesta etapa treinamos um modelo supervisionado para classificar reviews\n",
        "em **negativo, neutro ou positivo**, a partir da nota atribu√≠da.\n",
        "\n",
        "**Essa abordagem √© amplamente utilizada em:**\n",
        "- Classifica√ß√£o de reviews\n",
        "- Detec√ß√£o de spam\n",
        "- Categoriza√ß√£o de tickets\n",
        "- Identifica√ß√£o de inten√ß√£o em chatbots"
      ],
      "metadata": {
        "id": "YEt3vuRd-ukx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üéØ **Cria√ß√£o da Vari√°vel Alvo**\n",
        "\n",
        "Para transformar o problema em uma tarefa de classifica√ß√£o supervisionada,\n",
        "convertimos a nota num√©rica (`rating`) em categorias de sentimento:\n",
        "\n",
        "- 1 ou 2 ‚Üí **negativo**\n",
        "- 3 ‚Üí **neutro**\n",
        "- 4 ou 5 ‚Üí **positivo**\n",
        "\n",
        "**Aqui definimos a classe que o modelo ir√° prever, baseada na nota atribu√≠da pelo usu√°rio.**"
      ],
      "metadata": {
        "id": "tTDLSNz2_GRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classificar_rating(r):\n",
        "    if r <= 2:\n",
        "        return \"negativo\"\n",
        "    elif r == 3:\n",
        "        return \"neutro\"\n",
        "    else:\n",
        "        return \"positivo\"\n",
        "\n",
        "df[\"classe_sentimento\"] = df[\"rating\"].apply(classificar_rating)"
      ],
      "metadata": {
        "id": "anCH7yxr_P9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîé **Defini√ß√£o das vari√°veis**\n",
        "\n",
        "Aqui separamos o que ser√° usado como entrada **(texto)**\n",
        "e o que o modelo deve prever **(classe de sentimento)**."
      ],
      "metadata": {
        "id": "ztEyao3I_YML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[\"content\"].astype(str)\n",
        "y = df[\"classe_sentimento\"]"
      ],
      "metadata": {
        "id": "L_4VQrt-_ksx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÇÔ∏è **Divis√£o em Treino e Teste**\n",
        "\n",
        "Separamos os dados em **80% treino** e **20% teste**.\n",
        "\n",
        "O objetivo √© treinar o modelo em uma parte dos dados\n",
        "e avaliar seu desempenho em dados n√£o vistos garantindo uma avalia√ß√£o mais confi√°vel.\n"
      ],
      "metadata": {
        "id": "X6YQccZRAIZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "9XC6CuR3ASRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üî§ **Vetoriza√ß√£o com TF-IDF**\n",
        "\n",
        "- Transforma√ß√£o do texto em representa√ß√£o num√©rica.\n",
        "\n",
        "- max_features=5000 limita o vocabul√°rio\n",
        "\n",
        "- O modelo passa a trabalhar com vetores num√©ricos"
      ],
      "metadata": {
        "id": "SBaYharfAanx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vetorizador = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    stop_words=None\n",
        ")\n",
        "\n",
        "X_treino_vet = vetorizador.fit_transform(X_treino)\n",
        "X_teste_vet = vetorizador.transform(X_teste)"
      ],
      "metadata": {
        "id": "h69lf6xsAiRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìà **Treinamento do Modelo**\n",
        "\n",
        "Treinamos uma Regress√£o Log√≠stica com **balanceamento de classes** para lidar com desbalanceamento do dataset."
      ],
      "metadata": {
        "id": "PCWLYCqsArbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "modelo.fit(X_treino_vet, y_treino)"
      ],
      "metadata": {
        "id": "UYCcqCbyAvYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîÆ**Realiza√ß√£o das Previs√µes**\n",
        "Aplicamos o modelo no conjunto de teste.\n",
        "\n",
        "**A vari√°vel predicoes** foi utilizada na etapa de avalia√ß√£o do modelo, sendo essencial para o **c√°lculo das m√©tricas de desempenho**, como **accuracy** e **relat√≥rio de classifica√ß√£o**, podendo ainda ser explorada em an√°lises adicionais de erro."
      ],
      "metadata": {
        "id": "a3nacQLUA2V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicoes = modelo.predict(X_teste_vet)"
      ],
      "metadata": {
        "id": "FrxP8abyA8qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìä**Avalia√ß√£o do Modelo**\n",
        "\n",
        "Avaliamos o desempenho utilizando:\n",
        "\n",
        "- Accuracy\n",
        "- Precision\n",
        "- Recall\n",
        "- F1-score"
      ],
      "metadata": {
        "id": "1KcyAzKgA_r1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_teste, predicoes))\n",
        "print(\"\\nRelat√≥rio de classifica√ß√£o:\")\n",
        "print(classification_report(y_teste, predicoes))"
      ],
      "metadata": {
        "id": "mQ1cxeM2BENq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìä **Interpreta√ß√£o dos Resultados**\n",
        "\n",
        "O modelo alcan√ßou **86% de acur√°cia**, com desempenho elevado na classe **positiva**, que concentra a maior parte das amostras.\n",
        "\n",
        "As classes **negativa** e principalmente **neutra** apresentaram m√©tricas inferiores, refletindo o desbalanceamento do dataset.\n",
        "\n",
        "Foi utilizado `class_weight=\"balanced\"` na Regress√£o Log√≠stica para tentar reduzir esse efeito, ajustando o peso das classes minorit√°rias durante o treinamento. Ainda assim, observa-se que o desbalanceamento impacta o desempenho final."
      ],
      "metadata": {
        "id": "lxsxn1CXBnuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß™**Teste com Novos Textos**\n",
        "\n",
        "Aplica√ß√£o pr√°tica do modelo em exemplos manuais."
      ],
      "metadata": {
        "id": "4beNMW8tBuyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo 1\n",
        "texto = ['Gostei muito, indico.']\n",
        "texto_vet = vetorizador.transform(texto)\n",
        "print(\"Predi√ß√£o:\", modelo.predict(texto_vet)[0])\n",
        "\n",
        "# Exemplo 2\n",
        "texto = ['At√© que √© bom.']\n",
        "texto_vet = vetorizador.transform(texto)\n",
        "print(\"Predi√ß√£o:\", modelo.predict(texto_vet)[0])\n",
        "\n",
        "# Exemplo 3\n",
        "texto = ['P√©ssimo produto, odiei o cheiro.']\n",
        "texto_vet = vetorizador.transform(texto)\n",
        "print(\"Predi√ß√£o:\", modelo.predict(texto_vet)[0])"
      ],
      "metadata": {
        "id": "RXsB6d0GBypM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üìå Conclus√£o**\n",
        "\n",
        "Neste projeto aplicamos um pipeline completo de NLP, incluindo:\n",
        "\n",
        "- Pr√©-processamento textual  \n",
        "- Representa√ß√£o vetorial (BoW e TF-IDF)  \n",
        "- Modelagem supervisionada  \n",
        "- Topic Modeling (LDA)  \n",
        "- Similaridade textual  \n",
        "- An√°lise com Transformers  \n",
        "\n",
        "O teste com novos textos demonstra a aplica√ß√£o pr√°tica do modelo,\n",
        "mostrando sua capacidade de generalizar para avalia√ß√µes n√£o vistas.\n",
        "\n",
        "Como pr√≥ximos passos, seria poss√≠vel:\n",
        "- Ajustar hiperpar√¢metros  \n",
        "- Aplicar t√©cnicas de balanceamento mais avan√ßadas  \n",
        "- Comparar com modelos baseados em Transformers  \n",
        "\n",
        "**O projeto evidencia a aplica√ß√£o integrada de t√©cnicas cl√°ssicas e modernas de NLP em um cen√°rio real de reviews de e-commerce.**"
      ],
      "metadata": {
        "id": "uEHVIqxzCB1n"
      }
    }
  ]
}